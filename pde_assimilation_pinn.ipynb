{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db8ea6f9",
   "metadata": {},
   "source": [
    "# Zadanie 6 — PINN dla PDE (porównanie z PDE i ODE)\n",
    "\n",
    "Cel:\n",
    "1) Stworzyć fizycznie informowaną sieć (PINN) aproksymującą pola S(x,y,t), R(x,y,t), I(x,y,t), C(x,y,t).\n",
    "2) Trenować PINN na:\n",
    "   - resztach równań PDE (fizyka),\n",
    "   - warunkach początkowych i brzegowych,\n",
    "   - słabych danych TB(t)=∬(S+R) dxdy z PDE (po asymilacji).\n",
    "3) Porównać predykcję PINN z symulacją PDE oraz z modelem ODE (parametry z asymilacji).\n",
    "Zapisy: figi → `figs/`, dane → `out/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8569ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math, time, random, sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Path(\"figs\").mkdir(exist_ok=True)\n",
    "Path(\"out\").mkdir(exist_ok=True)\n",
    "\n",
    "def savefig_fig(name, dpi=160):\n",
    "    if not str(name).startswith(\"figs/\"):\n",
    "        name = f\"figs/{name}\"\n",
    "    plt.savefig(name, dpi=dpi, bbox_inches=\"tight\")\n",
    "    print(f\"[Zapisano wykres] {name}\")\n",
    "\n",
    "def save_json(obj, path):\n",
    "    if not str(path).startswith(\"out/\"):\n",
    "        path = f\"out/{path}\"\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "    print(f\"[Zapisano JSON] {path}\")\n",
    "\n",
    "# Reproducowalność\n",
    "np.random.seed(123)\n",
    "random.seed(123)\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615bb923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Próba importu Twojego modułu PDE (Zadanie 2)\n",
    "import importlib.util\n",
    "\n",
    "PDE_OK = True\n",
    "try:\n",
    "    candidates = [\"tumor_diffusion_pde_analysis_annotated.py\", \"tumor_diffusion_pde_analysis.py\"]\n",
    "    pdemod = None\n",
    "    for cand in candidates:\n",
    "        if Path(cand).exists():\n",
    "            spec = importlib.util.spec_from_file_location(\"pdemod\", cand)\n",
    "            pdemod = importlib.util.module_from_spec(spec)\n",
    "            sys.modules[\"pdemod\"] = pdemod\n",
    "            spec.loader.exec_module(pdemod)\n",
    "            break\n",
    "    if pdemod is None:\n",
    "        raise FileNotFoundError(\"Nie znaleziono pliku modułu PDE.\")\n",
    "    Grid = pdemod.Grid\n",
    "    Params = pdemod.Params\n",
    "    run_simulation = pdemod.run_simulation\n",
    "    p_base = pdemod.p\n",
    "    print(\"[OK] Moduł PDE załadowany.\")\n",
    "except Exception as e:\n",
    "    PDE_OK = False\n",
    "    print(\"Uwaga: nie udało się załadować modułu PDE:\", e)\n",
    "\n",
    "# 2) ODE (z Zad. 5) — tylko do porównań TB(t)\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ODEParams:\n",
    "    rho_S: float = 0.04\n",
    "    rho_R: float = 0.03\n",
    "    K: float = 1.0\n",
    "    alpha_S: float = 0.8\n",
    "    alpha_R: float = 0.12\n",
    "    sigma: float = 0.05\n",
    "    delta: float = 0.1\n",
    "    gamma_S: float = 0.02\n",
    "    gamma_R: float = 0.02\n",
    "    lam: float = 0.2\n",
    "    beta: float = 0.0\n",
    "    mu_max: float = 0.05\n",
    "    C50: float = 0.2\n",
    "    m_hill: int = 3\n",
    "    dose_type: str = \"bolus_periodic\"\n",
    "    dose_A: float = 1.0\n",
    "    dose_period: float = 5.0\n",
    "    infusion_rate: float = 0.0\n",
    "\n",
    "def mu_of_C(C, mu_max, C50, m):\n",
    "    Cn = max(C, 0.0)\n",
    "    r = (Cn/(C50+1e-12))**m\n",
    "    return mu_max * (r/(1+r))\n",
    "\n",
    "def dosing_term_exact(t, dt, period, A):\n",
    "    tau = 0.01*period\n",
    "    t0 = (t // period) * period\n",
    "    start, end = t0, t0+tau\n",
    "    overlap = max(0.0, min(t+dt, end)-max(t, start))\n",
    "    return (A/tau)*(overlap/max(dt,1e-12))\n",
    "\n",
    "def ode_rhs(t, y, p: ODEParams, dt_for_dose):\n",
    "    S, R, I, C = y\n",
    "    N = S + R\n",
    "    dS = p.rho_S*S*(1-N/p.K) - p.alpha_S*C*S - p.gamma_S*I*S\n",
    "    dR = p.rho_R*R*(1-N/p.K) - p.alpha_R*C*R - p.gamma_R*I*R\n",
    "    dS -= mu_of_C(C, p.mu_max, p.C50, p.m_hill) * S\n",
    "    dR += mu_of_C(C, p.mu_max, p.C50, p.m_hill) * S\n",
    "    dI = p.sigma*N - p.delta*I\n",
    "    dC = -p.lam*C - p.beta*C*N\n",
    "    I_in = dosing_term_exact(t, dt_for_dose, p.dose_period, p.dose_A) if p.dose_type==\"bolus_periodic\" else 0.0\n",
    "    dC += I_in\n",
    "    return np.array([dS,dR,dI,dC], dtype=float)\n",
    "\n",
    "from scipy.integrate import solve_ivp\n",
    "def simulate_ode(p: ODEParams, y0, t_eval):\n",
    "    dt = np.mean(np.diff(t_eval)) if len(t_eval)>1 else 1e-2\n",
    "    fun = lambda t,y: ode_rhs(t,y,p,dt)\n",
    "    sol = solve_ivp(fun, (t_eval[0], t_eval[-1]), y0, t_eval=t_eval, rtol=1e-7, atol=1e-9)\n",
    "    Y = sol.y.T\n",
    "    return {\"t\": t_eval, \"S\": Y[:,0], \"R\": Y[:,1], \"I\": Y[:,2], \"C\": Y[:,3], \"TB\": Y[:,0]+Y[:,1]}\n",
    "\n",
    "# 3) Wczytaj parametry po asymilacji (preferencyjnie 3D-Var large → medium → small; fallback: ABC)\n",
    "def load_assimilated_params():\n",
    "    order = [\"out/3dvar_large_summary.json\", \"out/3dvar_medium_summary.json\", \"out/3dvar_small_summary.json\",\n",
    "             \"out/abc_large_summary.json\", \"out/abc_medium_summary.json\", \"out/abc_small_summary.json\"]\n",
    "    for path in order:\n",
    "        if Path(path).exists():\n",
    "            with open(path, \"r\") as f:\n",
    "                js = json.load(f)\n",
    "            if \"theta_opt\" in js:\n",
    "                alpha_S, mu_max, lam = js[\"theta_opt\"]\n",
    "            else:\n",
    "                alpha_S, mu_max, lam = js[\"theta_map\"]\n",
    "            return float(alpha_S), float(mu_max), float(lam), path\n",
    "    # fallback — bazowe\n",
    "    return p_base.alpha_S, p_base.mu_max, p_base.lam, \"baseline(p_base)\"\n",
    "\n",
    "alpha_S_assim, mu_max_assim, lam_assim, src = load_assimilated_params()\n",
    "print(f\"[PARAMS] Źródło: {src}  →  alpha_S={alpha_S_assim:.3f}, mu_max={mu_max_assim:.3f}, lam={lam_assim:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fda2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === KOMÓRKA 4 — GENERACJA DANYCH PDE + INICJALIZACJA IC (bez S_mean w traj) ===\n",
    "\n",
    "# Horyzont i siatki\n",
    "T_end = 6.0\n",
    "t_eval = np.linspace(0.0, T_end, 121)  # co 0.05\n",
    "Nx_data, Ny_data = 64, 64              # siatka do generacji danych i ewaluacji\n",
    "\n",
    "if not PDE_OK:\n",
    "    raise RuntimeError(\"Moduł PDE wymagany do Zadania 6 (PINN).\")\n",
    "\n",
    "# Ustaw parametry PDE po asymilacji\n",
    "p_assim = Params(**vars(p_base))\n",
    "p_assim.alpha_S = alpha_S_assim\n",
    "p_assim.mu_max  = mu_max_assim\n",
    "p_assim.lam     = lam_assim\n",
    "\n",
    "# Symulacja PDE (semi-implicit) → TB(t) oraz stany końcowe do wizualizacji\n",
    "grid = Grid(Nx=Nx_data, Ny=Ny_data, Lx=1.0, Ly=1.0)\n",
    "(S_end, R_end, I_end, C_end), traj, info = run_simulation(\n",
    "    solver_name=\"semi_implicit\",\n",
    "    grid=grid, p=p_assim,\n",
    "    T=T_end, dt=None, save_every=max(1, len(t_eval)//120), theta=0.5\n",
    ")\n",
    "\n",
    "# Referencja TB(t) z traj\n",
    "t_traj = np.array([row[\"t\"] for row in traj])\n",
    "TB_traj = np.array([row[\"tumor_burden\"] for row in traj])\n",
    "TB_pde = np.interp(t_eval, t_traj, TB_traj)\n",
    "\n",
    "# --- Inicjalizacja pól początkowych (IC) dla strat IC PINN ---\n",
    "S0_mat = R0_mat = I0_mat = C0_mat = None\n",
    "\n",
    "# 1) Preferuj wbudowaną funkcję inicjalizacji z modułu (jeśli istnieje)\n",
    "if hasattr(pdemod, \"initialize_fields\"):\n",
    "    try:\n",
    "        S0_mat, R0_mat, I0_mat, C0_mat = pdemod.initialize_fields(grid)\n",
    "        print(\"[IC] Użyto pdemod.initialize_fields(grid).\")\n",
    "    except Exception as e:\n",
    "        print(\"[IC] initialize_fields() nie powiodło się:\", e)\n",
    "\n",
    "# 2) Fallback: ręczna inicjalizacja spójna z wcześniejszymi zadaniami\n",
    "if S0_mat is None:\n",
    "    xs = np.linspace(0, 1, Nx_data)\n",
    "    ys = np.linspace(0, 1, Ny_data)\n",
    "    Xg, Yg = np.meshgrid(xs, ys, indexing=\"ij\")\n",
    "\n",
    "    # Gauss dla S wokół (0.5, 0.5)\n",
    "    sigma0 = 0.12\n",
    "    A_S = 1.0e-3  # niewielka masa początkowa (jak w naszych wcześniejszych symulacjach)\n",
    "    r2 = (Xg - 0.5)**2 + (Yg - 0.5)**2\n",
    "    S0_mat = A_S * np.exp(-r2 / (2*sigma0**2))\n",
    "\n",
    "    # Brak początkowych komórek opornych\n",
    "    R0_mat = np.zeros_like(S0_mat)\n",
    "\n",
    "    # Niewielka dawka immunologiczna\n",
    "    I0_mat = 0.02 * np.exp(-r2 / (2*(0.18**2)))\n",
    "\n",
    "    # Jednorodne C: z parametrów jeśli dostępne, inaczej 0.5\n",
    "    C_init_val = float(getattr(p_assim, \"C_init\", 0.5))\n",
    "    C0_mat = np.full_like(S0_mat, C_init_val)\n",
    "\n",
    "    print(\"[IC] Użyto ręcznej inicjalizacji: Gaussian S, R=0, I małe, C=const.\")\n",
    "\n",
    "# Losowania punktów treningowych (tak jak wcześniej)\n",
    "n_phys   = 6000\n",
    "n_ic     = 2000\n",
    "n_bc     = 2000\n",
    "n_tb     = 200\n",
    "\n",
    "xs = np.linspace(0,1,Nx_data); ys = np.linspace(0,1,Ny_data)\n",
    "\n",
    "def sample_uniform_xy(n):\n",
    "    return np.random.rand(n,1), np.random.rand(n,1)\n",
    "\n",
    "# Kolokacja (t,x,y)\n",
    "t_phys = np.random.rand(n_phys,1) * T_end\n",
    "x_phys, y_phys = sample_uniform_xy(n_phys)\n",
    "\n",
    "# IC: t=0 z etykietą z macierzy IC\n",
    "ix_ic = np.random.randint(0, Nx_data, size=n_ic)\n",
    "iy_ic = np.random.randint(0, Ny_data, size=n_ic)\n",
    "t_ic  = np.zeros((n_ic,1))\n",
    "x_ic  = xs[ix_ic][:,None]\n",
    "y_ic  = ys[iy_ic][:,None]\n",
    "S_ic  = S0_mat[ix_ic, iy_ic][:,None]\n",
    "R_ic  = R0_mat[ix_ic, iy_ic][:,None]\n",
    "I_ic  = I0_mat[ix_ic, iy_ic][:,None]\n",
    "C_ic  = C0_mat[ix_ic, iy_ic][:,None]\n",
    "\n",
    "# BC: próbki na brzegu\n",
    "def sample_boundary(n):\n",
    "    sel = np.random.randint(0,4,size=n)\n",
    "    t = np.random.rand(n,1)*T_end\n",
    "    x = np.random.rand(n,1)\n",
    "    y = np.random.rand(n,1)\n",
    "    nx = np.zeros((n,1)); ny = np.zeros((n,1))\n",
    "    for i,s in enumerate(sel):\n",
    "        if s==0:   x[i]=0.0; nx[i]=-1.0; ny[i]=0.0\n",
    "        elif s==1: x[i]=1.0; nx[i]= 1.0; ny[i]=0.0\n",
    "        elif s==2: y[i]=0.0; nx[i]= 0.0; ny[i]=-1.0\n",
    "        else:      y[i]=1.0; nx[i]= 0.0; ny[i]= 1.0\n",
    "    return t,x,y,nx,ny\n",
    "\n",
    "t_bc, x_bc, y_bc, nx_bc, ny_bc = sample_boundary(n_bc)\n",
    "\n",
    "# TB: losowe czasy i TB_pde(t) jako „dane” dla straty TB\n",
    "it_tb = np.random.randint(0, len(t_eval), size=n_tb)\n",
    "t_tb  = t_eval[it_tb][:,None]\n",
    "TB_tb = TB_pde[it_tb][:,None]\n",
    "\n",
    "# Zapis referencji TB\n",
    "pd.DataFrame({\"t\": t_eval, \"TB_pde\": TB_pde}).to_csv(\"out/pinn_tb_reference.csv\", index=False)\n",
    "print(\"[Zapisano] out/pinn_tb_reference.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93213704",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim=3, out_dim=4, width=128, depth=6):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(in_dim, width))\n",
    "        layers.append(nn.Tanh())\n",
    "        for _ in range(depth-1):\n",
    "            layers.append(nn.Linear(width, width))\n",
    "            layers.append(nn.Tanh())\n",
    "        layers.append(nn.Linear(width, out_dim))  # [S,R,I,C]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self, txys):\n",
    "        return self.net(txys)\n",
    "\n",
    "pinn = MLP().to(device)\n",
    "sum(p.numel() for p in pinn.parameters())/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081f458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametry fizyczne z p_assim (dyfuzje i współczynniki)\n",
    "D_S = torch.tensor(float(p_assim.D_S), device=device)\n",
    "D_R = torch.tensor(float(p_assim.D_R), device=device)\n",
    "D_I = torch.tensor(float(p_assim.D_I), device=device)\n",
    "D_C = torch.tensor(float(p_assim.D_C), device=device)\n",
    "\n",
    "rho_S   = torch.tensor(float(p_assim.rho_S), device=device)\n",
    "rho_R   = torch.tensor(float(p_assim.rho_R), device=device)\n",
    "Kcap    = torch.tensor(float(p_assim.K), device=device)\n",
    "alpha_S = torch.tensor(float(p_assim.alpha_S), device=device)\n",
    "alpha_R = torch.tensor(float(p_assim.alpha_R), device=device)\n",
    "sigma   = torch.tensor(float(p_assim.sigma), device=device)\n",
    "delta   = torch.tensor(float(p_assim.delta), device=device)\n",
    "gamma_S = torch.tensor(float(p_assim.gamma_S), device=device)\n",
    "gamma_R = torch.tensor(float(p_assim.gamma_R), device=device)\n",
    "lam     = torch.tensor(float(p_assim.lam), device=device)\n",
    "beta    = torch.tensor(float(p_assim.beta), device=device)\n",
    "mu_max  = torch.tensor(float(p_assim.mu_max), device=device)\n",
    "C50     = torch.tensor(float(p_assim.C50), device=device)\n",
    "m_hill  = int(p_assim.m_hill)\n",
    "\n",
    "def mu_hill(C):\n",
    "    Cpos = torch.clamp(C, min=0.0)\n",
    "    r = (Cpos/(C50+1e-12))**m_hill\n",
    "    return mu_max * (r/(1.0 + r))\n",
    "\n",
    "def laplacian(u, x, y):\n",
    "    grads = torch.autograd.grad(u, (x,y), grad_outputs=torch.ones_like(u), create_graph=True)\n",
    "    ux, uy = grads[0], grads[1]\n",
    "    uxx = torch.autograd.grad(ux, x, grad_outputs=torch.ones_like(ux), create_graph=True)[0]\n",
    "    uyy = torch.autograd.grad(uy, y, grad_outputs=torch.ones_like(uy), create_graph=True)[0]\n",
    "    return uxx + uyy, ux, uy\n",
    "\n",
    "def pde_residuals(t, x, y):\n",
    "    \"\"\"Zwraca reszty PDE dla S,R,I,C oraz pochodne normalne do warunków brzegowych.\"\"\"\n",
    "    t.requires_grad_(True); x.requires_grad_(True); y.requires_grad_(True)\n",
    "    inp = torch.cat([t, x, y], dim=1).to(device)\n",
    "    out = pinn(inp)\n",
    "    S, R, I, C = out[:,0:1], out[:,1:2], out[:,2:3], out[:,3:4]\n",
    "    N = S + R\n",
    "\n",
    "    # pochodne czasowe\n",
    "    dSdt = torch.autograd.grad(S, t, grad_outputs=torch.ones_like(S), create_graph=True)[0]\n",
    "    dRdt = torch.autograd.grad(R, t, grad_outputs=torch.ones_like(R), create_graph=True)[0]\n",
    "    dIdt = torch.autograd.grad(I, t, grad_outputs=torch.ones_like(I), create_graph=True)[0]\n",
    "    dCdt = torch.autograd.grad(C, t, grad_outputs=torch.ones_like(C), create_graph=True)[0]\n",
    "\n",
    "    # laplasjany\n",
    "    lapS, _, _ = laplacian(S, x, y)\n",
    "    lapR, _, _ = laplacian(R, x, y)\n",
    "    lapI, _, _ = laplacian(I, x, y)\n",
    "    lapC, _, _ = laplacian(C, x, y)\n",
    "\n",
    "    # reakcje\n",
    "    mu = mu_hill(C)\n",
    "    fS = dSdt - (D_S*lapS + rho_S*S*(1.0 - N/Kcap) - alpha_S*C*S - gamma_S*I*S - mu*S)\n",
    "    fR = dRdt - (D_R*lapR + rho_R*R*(1.0 - N/Kcap) - alpha_R*C*R - gamma_R*I*R + mu*S)\n",
    "    fI = dIdt - (D_I*lapI + sigma*N - delta*I)\n",
    "    # brak jawnego źródła C poza bolusem — w PINN bez impulsów: -lam*C - beta*C*N\n",
    "    fC = dCdt - (D_C*lapC - lam*C - beta*C*N)\n",
    "\n",
    "    return fS, fR, fI, fC, S, R, I, C\n",
    "\n",
    "# Tensory danych do trenowania\n",
    "to_t = lambda a: torch.tensor(a, dtype=torch.float32, device=device)\n",
    "\n",
    "t_phys_t = to_t(t_phys); x_phys_t = to_t(x_phys); y_phys_t = to_t(y_phys)\n",
    "t_ic_t   = to_t(t_ic);   x_ic_t   = to_t(x_ic);   y_ic_t   = to_t(y_ic)\n",
    "S_ic_t   = to_t(S_ic);   R_ic_t   = to_t(R_ic);   I_ic_t   = to_t(I_ic);   C_ic_t = to_t(C_ic)\n",
    "\n",
    "t_bc_t = to_t(t_bc); x_bc_t = to_t(x_bc); y_bc_t = to_t(y_bc); nx_bc_t = to_t(nx_bc); ny_bc_t = to_t(ny_bc)\n",
    "t_tb_t = to_t(t_tb); TB_tb_t = to_t(TB_tb)\n",
    "\n",
    "# Funkcja TB z PINN — całkowanie po siatce (prosty kwadratur prostokątów)\n",
    "xs_t = to_t(xs[:,None]); ys_t = to_t(ys[:,None])\n",
    "XG = xs_t.repeat(1,Ny_data).view(-1,1)\n",
    "YG = ys_t.T.repeat(Nx_data,1).view(-1,1)\n",
    "dA = (1.0/(Nx_data-1))*(1.0/(Ny_data-1))  # ~dx*dy\n",
    "\n",
    "def pinn_TB_at_time(t_scalar):\n",
    "    tcol = torch.full((Nx_data*Ny_data,1), float(t_scalar), device=device)\n",
    "    with torch.no_grad():\n",
    "        out = pinn(torch.cat([tcol, XG, YG], dim=1))\n",
    "        Sg = out[:,0:1]; Rg = out[:,1:2]\n",
    "        TB = (Sg + Rg).mean()  # średnia ~ całka / pole (jednostkowa dziedzina)\n",
    "    return float(TB.detach().cpu().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c458bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wagi składników straty\n",
    "w_phys = 1.0\n",
    "w_ic   = 5.0\n",
    "w_bc   = 1.0\n",
    "w_tb   = 10.0  # TB daje globalne „przyciąganie” do trajektorii PDE\n",
    "\n",
    "optimizer = optim.Adam(pinn.parameters(), lr=1e-3)\n",
    "\n",
    "def bc_penalty(t, x, y, nx, ny):\n",
    "    # Neumann d/dn ~ grad·n dla S,R,I  → ~0\n",
    "    # Robin dla C: dC/dn + beta_robin*C ≈ 0 (jeśli beta>0), tu użyjemy p_assim.beta_robin_C jeśli jest; fallback: 0\n",
    "    fS, fR, fI, fC, S, R, I, C = pde_residuals(t, x, y)\n",
    "    # gradienty przestrzenne do strumieni\n",
    "    t.requires_grad_(True); x.requires_grad_(True); y.requires_grad_(True)\n",
    "    out = pinn(torch.cat([t,x,y], dim=1))\n",
    "    Sg,Rg,Ig,Cg = out[:,0:1],out[:,1:2],out[:,2:3],out[:,3:4]\n",
    "    _, Sx, Sy = laplacian(Sg, x, y)\n",
    "    _, Rx, Ry = laplacian(Rg, x, y)\n",
    "    _, Ix, Iy = laplacian(Ig, x, y)\n",
    "    _, Cx, Cy = laplacian(Cg, x, y)\n",
    "    dnS = Sx*nx + Sy*ny\n",
    "    dnR = Rx*nx + Ry*ny\n",
    "    dnI = Ix*nx + Iy*ny\n",
    "    dnC = Cx*nx + Cy*ny\n",
    "    beta_robin = getattr(p_assim, \"beta_robin_C\", 0.0)\n",
    "    robin = dnC + float(beta_robin)*Cg\n",
    "    return (dnS**2).mean() + (dnR**2).mean() + (dnI**2).mean() + (robin**2).mean()\n",
    "\n",
    "def ic_penalty():\n",
    "    t,x,y = t_ic_t, x_ic_t, y_ic_t\n",
    "    out = pinn(torch.cat([t,x,y], dim=1))\n",
    "    Sg,Rg,Ig,Cg = out[:,0:1],out[:,1:2],out[:,2:3],out[:,3:4]\n",
    "    return ((Sg-S_ic_t)**2).mean() + ((Rg-R_ic_t)**2).mean() + ((Ig-I_ic_t)**2).mean() + ((Cg-C_ic_t)**2).mean()\n",
    "\n",
    "def tb_penalty():\n",
    "    # porównujemy średnią TB w wylosowanych chwilach czasu z referencją z PDE\n",
    "    loss = 0.0\n",
    "    for ti, TB_ref in zip(t_tb_t, TB_tb_t):\n",
    "        tb_pred = pinn_TB_at_time(float(ti.item()))\n",
    "        loss += (tb_pred - float(TB_ref.item()))**2\n",
    "    return torch.tensor(loss / len(t_tb_t), dtype=torch.float32, device=device)\n",
    "\n",
    "history = []\n",
    "epochs = 4000  # możesz zmniejszyć do 1500 przy słabszym GPU/CPU\n",
    "t0 = time.time()\n",
    "for ep in range(1, epochs+1):\n",
    "    optimizer.zero_grad()\n",
    "    fS, fR, fI, fC, _,_,_,_ = pde_residuals(t_phys_t, x_phys_t, y_phys_t)\n",
    "    L_phys = (fS**2).mean() + (fR**2).mean() + (fI**2).mean() + (fC**2).mean()\n",
    "    L_ic   = ic_penalty()\n",
    "    L_bc   = bc_penalty(t_bc_t, x_bc_t, y_bc_t, nx_bc_t, ny_bc_t)\n",
    "    L_tb   = tb_penalty()\n",
    "    loss = w_phys*L_phys + w_ic*L_ic + w_bc*L_bc + w_tb*L_tb\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if ep % 100 == 0 or ep == 1:\n",
    "        elapsed = time.time()-t0\n",
    "        history.append({\"ep\":ep, \"L\":float(loss.item()), \"L_phys\":float(L_phys.item()),\n",
    "                        \"L_ic\":float(L_ic.item()), \"L_bc\":float(L_bc.item()), \"L_tb\":float(L_tb.item()),\n",
    "                        \"time\":elapsed})\n",
    "        print(f\"[{ep:5d}] L={loss.item():.3e}  phys={L_phys.item():.3e}  ic={L_ic.item():.3e}  bc={L_bc.item():.3e}  tb={L_tb.item():.3e}\")\n",
    "\n",
    "pd.DataFrame(history).to_csv(\"out/pinn_training_history.csv\", index=False)\n",
    "print(\"[Zapisano] out/pinn_training_history.csv\")\n",
    "\n",
    "torch.save(pinn.state_dict(), \"out/pinn_model.pt\")\n",
    "print(\"[Zapisano] out/pinn_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9c4b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PINN → TB(t)\n",
    "TB_pinn = np.array([pinn_TB_at_time(ti) for ti in t_eval])\n",
    "\n",
    "# ODE → TB(t) (te same parametry co do PDE po asymilacji)\n",
    "TB0 = TB_pde[0]\n",
    "y0_ode = np.array([0.9*TB0, 0.1*TB0, 0.02, 0.0])\n",
    "p_ode = ODEParams(alpha_S=float(alpha_S_assim), mu_max=float(mu_max_assim), lam=float(lam_assim))\n",
    "sim_ode = simulate_ode(p_ode, y0_ode, t_eval)\n",
    "TB_ode = sim_ode[\"TB\"]\n",
    "\n",
    "# RMSE\n",
    "def rmse(a,b): return float(np.sqrt(np.mean((np.asarray(a)-np.asarray(b))**2)))\n",
    "\n",
    "metrics = {\n",
    "    \"rmse_pinn_vs_pde\": rmse(TB_pinn, TB_pde),\n",
    "    \"rmse_ode_vs_pde\":  rmse(TB_ode,  TB_pde),\n",
    "    \"rmse_pinn_vs_ode\": rmse(TB_pinn, TB_ode)\n",
    "}\n",
    "save_json(metrics, \"out/pinn_metrics.json\")\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a83a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7.5,4.6))\n",
    "plt.plot(t_eval, TB_pde, label=\"PDE (ref.)\", lw=2)\n",
    "plt.plot(t_eval, TB_pinn, \"--\", label=\"PINN\", lw=2)\n",
    "plt.plot(t_eval, TB_ode,  \":\", label=\"ODE\", lw=2)\n",
    "plt.xlabel(\"t\"); plt.ylabel(\"TB(t)\")\n",
    "plt.title(\"TB(t): PINN vs PDE vs ODE\")\n",
    "plt.legend()\n",
    "savefig_fig(\"pinn_tb_compare.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa5511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ewaluacja PINN na siatce w chwili t=T_end\n",
    "with torch.no_grad():\n",
    "    tcol = torch.full((Nx_data*Ny_data,1), T_end, device=device)\n",
    "    out = pinn(torch.cat([tcol, XG, YG], dim=1))\n",
    "    Sg = out[:,0].reshape(Nx_data,Ny_data).cpu().numpy()\n",
    "    Rg = out[:,1].reshape(Nx_data,Ny_data).cpu().numpy()\n",
    "    Ig = out[:,2].reshape(Nx_data,Ny_data).cpu().numpy()\n",
    "    Cg = out[:,3].reshape(Nx_data,Ny_data).cpu().numpy()\n",
    "\n",
    "vmax_S = max(Sg.max(), S_end.max()); vmax_R = max(Rg.max(), R_end.max())\n",
    "vmax_I = max(Ig.max(), I_end.max());   vmax_C = max(Cg.max(), C_end.max())\n",
    "\n",
    "def imshow_grid(Z, title, vmax=None):\n",
    "    plt.figure(figsize=(5.2,4.4))\n",
    "    plt.imshow(Z.T, origin=\"lower\", extent=(0,1,0,1), cmap=\"viridis\", vmin=0, vmax=vmax)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    savefig_fig(title.replace(\" \",\"_\")+\".png\"); plt.show()\n",
    "\n",
    "imshow_grid(S_end, \"PDE_S_final\", vmax_S)\n",
    "imshow_grid(Sg,    \"PINN_S_final\", vmax_S)\n",
    "imshow_grid(R_end, \"PDE_R_final\", vmax_R)\n",
    "imshow_grid(Rg,    \"PINN_R_final\", vmax_R)\n",
    "imshow_grid(I_end, \"PDE_I_final\", vmax_I)\n",
    "imshow_grid(Ig,    \"PINN_I_final\", vmax_I)\n",
    "imshow_grid(C_end, \"PDE_C_final\", vmax_C)\n",
    "imshow_grid(Cg,    \"PINN_C_final\", vmax_C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b79f605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zbiorcza tabela TB(t)\n",
    "df_tb = pd.DataFrame({\"t\": t_eval, \"TB_pde\": TB_pde, \"TB_pinn\": TB_pinn, \"TB_ode\": TB_ode})\n",
    "df_tb.to_csv(\"out/pinn_tb_curves.csv\", index=False)\n",
    "print(\"[Zapisano] out/pinn_tb_curves.csv\")\n",
    "\n",
    "# Raport metryk\n",
    "print(\"RMSE(PINN, PDE) =\", metrics[\"rmse_pinn_vs_pde\"])\n",
    "print(\"RMSE(ODE,  PDE) =\", metrics[\"rmse_ode_vs_pde\"])\n",
    "print(\"RMSE(PINN, ODE) =\", metrics[\"rmse_pinn_vs_ode\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7aa2fc",
   "metadata": {},
   "source": [
    "## Uwagi praktyczne\n",
    "- Jeśli trening jest zbyt wolny, zmniejsz liczność próbek: `n_phys`, `n_ic`, `n_bc`, `n_tb`, głębokość/ szerokość MLP, liczbę `epochs`.\n",
    "- Wagi `w_phys, w_ic, w_bc, w_tb` równoważą wpływ fizyki, warunków i danych TB — dostrojone „zdroworozsądkowo”.\n",
    "- PINN nie modeluje impulsowych zastrzyków w C (bolus) jawnie; ich efekt jest „wchłonięty” przez dopasowanie globalne TB(t).\n",
    "- Gdy chcesz ująć impulsy, dodaj do fC człon źródłowy zależny od czasu lub włącz dodatkowy składnik straty wymuszający kształt C(t)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
